{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluation\n",
    "In order to experiment with new models, we first need a way to evaluate the results we achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# We're using a document retriever class, to make it easier to perform the evaluator code on different models\n",
    "class DocumentRetriever:\n",
    "    all_docs = pd.read_csv(\"data/all_docs.csv\")\n",
    "    all_queries = pd.read_csv(\"data/dev_queries.csv\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_value_by_id_from_df(id, id_column, value_column, df):\n",
    "        value = df[df[id_column] == id][value_column].iat[0]\n",
    "        return value\n",
    "\n",
    "    @staticmethod\n",
    "    def query_nr_to_text(query_nr):\n",
    "        return DocumentRetriever.get_value_by_id_from_df(query_nr, 'Query_number', 'Query',\n",
    "                                                         DocumentRetriever.all_queries)\n",
    "\n",
    "    @staticmethod\n",
    "    def doc_nr_to_text(doc_number):\n",
    "        return DocumentRetriever.get_value_by_id_from_df(doc_number, 'doc_number', 'doc_text',\n",
    "                                                         DocumentRetriever.all_docs)\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def retrieve_documents(self, query_number, n):\n",
    "        # Return the n best recommendations (ordered by decreasing relevance) for given query\n",
    "        raise Exception(\"Function not implemented in subclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[476602, 432658, 429474, 346632, 122086, 362869, 60461, 417115, 29215, 467667]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LuceneRetriever(DocumentRetriever):\n",
    "    lucene_raw_retrievals = pd.read_csv(\"data/raw_dev_Lucene_retrievals.csv\")\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def retrieve_documents(self, query_number, n):\n",
    "        relevant_docs = self.lucene_raw_retrievals[self.lucene_raw_retrievals['Query_number'] == query_number]\n",
    "        top_n = relevant_docs.head(n)\n",
    "        return top_n['doc_number'].to_list()\n",
    "\n",
    "\n",
    "luceneRetriever = LuceneRetriever()\n",
    "results = luceneRetriever.retrieve_documents(1089071, 10)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GroundTruthRetriever(DocumentRetriever):\n",
    "    ground_truth = pd.read_csv(\"data/dev_data.csv\")\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def retrieve_documents(self, query_number, n):\n",
    "        #assert n is None # The truth has no limits, it just retrieves all relevant documents -> nevermind, the ground_truth is also ranked, so I can perfectly get a top-k\n",
    "        query_results = self.ground_truth[self.ground_truth['Query_number'] == query_number]\n",
    "        relevant_docs = query_results[query_results['label'] == 1]\n",
    "        top_n = relevant_docs.head(n)\n",
    "        return top_n['doc_number'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class ModelRater:\n",
    "    ground_truth_retriever = GroundTruthRetriever()\n",
    "    probe_data = pd.read_csv(\"data/dev_queries.csv\")\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def single_query_recall_precission(self, query_nr, n, retriever):\n",
    "        query_results = set(retriever.retrieve_documents(query_nr, n))\n",
    "        ground_truth = set(self.ground_truth_retriever.retrieve_documents(query_nr, n))\n",
    "\n",
    "        # Some of this code is based on https://stackoverflow.com/questions/55952408/how-to-calculate-precision-and-recall-of-2-lists-in-python\n",
    "        intersect_length = len(query_results.intersection(ground_truth))\n",
    "        precision = intersect_length / len(query_results)\n",
    "        recall = intersect_length / len(ground_truth)\n",
    "\n",
    "        # print(f\"R({recall}), P({precision})\")\n",
    "\n",
    "        return recall, precision\n",
    "\n",
    "    def get_rating(self, retriever: DocumentRetriever, n=10) -> (float, float):\n",
    "        # returns the recall, precision\n",
    "\n",
    "        precision_sum = 0\n",
    "        recall_sum = 0\n",
    "        query_count = 0\n",
    "        # For every query in probe data, determine the results\n",
    "        for counter, query in tqdm(self.probe_data.iterrows(), total=self.probe_data.shape[0]):\n",
    "            query_nr = query['Query_number']\n",
    "\n",
    "            recall, precision = self.single_query_recall_precission(query_nr, n, retriever)\n",
    "\n",
    "            precision_sum += precision\n",
    "            recall_sum += recall\n",
    "            query_count += 1\n",
    "\n",
    "        avg_precision = precision_sum / query_count\n",
    "        avg_recall = recall_sum / query_count\n",
    "\n",
    "        print(f\"Recall@{n}: {avg_recall}, Precision@{n}: {avg_precision}\")\n",
    "\n",
    "        return avg_recall, avg_precision\n",
    "\n",
    "\n",
    "rater = ModelRater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7296ff0c08fe47538933e273952d5d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/644 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 1.0, Precision@10: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just for testing, this should return 1, 1\n",
    "rater.get_rating(ModelRater.ground_truth_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6239a9e83bb044c09826620ed9a99f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/644 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.49958099181701693, Precision@10: 0.49642857142857183\n"
     ]
    }
   ],
   "source": [
    "recall, precision = rater.get_rating(luceneRetriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The problem in this comment has been fixed (and so it's outdated). You'll read more about the fix somewhere below, in the section \"Rater changes\".\n",
    "\n",
    "Copy of the output on which the comment was based:\n",
    "```\n",
    "Recall: 0.32744769762105247, Precision: 1.0\n",
    "```\n",
    "It's strange that the precision is always exactly 1.0. This is probably because the ground truth results (dev_data.csv) is based on the lucene retrievals (raw_dev_Lucene_retrievals.csv).\n",
    "\n",
    "## BM25 retrieval\n",
    "Another lexical search, which was mentioned in the SBERT-Documentation. Note that some of the methods here are partially copied from that documentation.\n",
    "\n",
    "We already defined a help function in the DocumentRetriever class to get the query given the query_nr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how does sperm develop'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DocumentRetriever.query_nr_to_text(1099178)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We also compare the results to lexical search (keyword search). Here, we use\n",
    "# the BM25 algorithm which is implemented in the rank_bm25 package.\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Bm25Retriever(DocumentRetriever):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.reverse_index = []\n",
    "        self.tokenized_corpus = []\n",
    "        for count, row in tqdm(DocumentRetriever.all_docs.iterrows(), total=DocumentRetriever.all_docs.shape[0]):\n",
    "            # Work with a smaller dataset when debugging\n",
    "            # if len(self.reverse_index) == 1000:\n",
    "            #     break\n",
    "            passage = str(row['doc_text'])\n",
    "            doc_nr = row['doc_number']\n",
    "            self.tokenized_corpus.append(self.bm25_tokenizer(passage))\n",
    "            self.reverse_index.append(doc_nr)\n",
    "\n",
    "        self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "\n",
    "    # We lower case our text and remove stop-words from indexing\n",
    "    @staticmethod\n",
    "    def bm25_tokenizer(text):\n",
    "        tokenized_doc = []\n",
    "        for token in text.lower().split():\n",
    "            token = token.strip(string.punctuation)\n",
    "\n",
    "            if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "                tokenized_doc.append(token)\n",
    "        return tokenized_doc\n",
    "\n",
    "    def search(self, query_text, n):\n",
    "        # This code is based on the code from sbert-doc.ipynb\n",
    "        bm25_scores = self.bm25.get_scores(self.bm25_tokenizer(query_text))\n",
    "        top_n = np.argpartition(bm25_scores, -n)[-n:]\n",
    "        bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "        bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "        results = []\n",
    "        for hit in bm25_hits:\n",
    "            results.append(self.reverse_index[hit['corpus_id']])\n",
    "        return results\n",
    "\n",
    "    def retrieve_documents(self, query_number, n):\n",
    "        return self.search(self.query_nr_to_text(query_number), n)\n",
    "\n",
    "\n",
    "bm25Retriever = Bm25Retriever()\n",
    "recall, precision = rater.get_rating(bm25Retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## MsMarco\n",
    "See what's the precision on the pretrained MsMarco bi-encoder and cross-encoder. Some of the methods are based on code from the `sbert-doc.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ReRankRetriever(DocumentRetriever):\n",
    "    def __init__(self, top_k=50):\n",
    "        \"\"\"\n",
    "        :param top_k: Number of variables to get with the first function\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.top_k = top_k  #Number of passages we want to select before reranking\n",
    "\n",
    "    def select_candidates(self, query, query_nr=None):\n",
    "        # Typically done by e.g. a bi-encoder\n",
    "        raise Exception(\"Not implemented\")\n",
    "\n",
    "    def rerank_candidates(self, candidates, query):\n",
    "        # Candidates is the output of the select_candidates function\n",
    "        # Typically done by e.g. a cross-encoder\n",
    "        raise Exception(\"Not implemented\")\n",
    "\n",
    "    def retrieve_documents(self, query_nr, n):\n",
    "        query = self.query_nr_to_text(query_nr)\n",
    "\n",
    "        # Find potentially relevant passages\n",
    "        hits = self.select_candidates(query, query_nr=query_nr)\n",
    "\n",
    "        # Re-rank those matches\n",
    "        ranked = self.rerank_candidates(hits, query)\n",
    "\n",
    "        return ranked[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class BiCrossRetriever(ReRankRetriever):\n",
    "    def __init__(self, bi_encoder_name='msmarco-bert-base-dot-v5',\n",
    "                 cross_encoder_name='cross-encoder/ms-marco-TinyBERT-L-2-v2'):\n",
    "        super().__init__()\n",
    "        print(\"Super inited\")\n",
    "\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"Warning: No GPU found. Please add GPU to your notebook\")\n",
    "\n",
    "        #We use the Bi-Encoder to encode all passages, so that we can use it with sematic search\n",
    "        self.bi_encoder = SentenceTransformer(bi_encoder_name)\n",
    "        self.bi_encoder.max_seq_length = 256  #Truncate long passages to 256 tokens\n",
    "\n",
    "        #The bi-encoder will retrieve 100 documents. We use a cross-encoder, to re-rank the results list to improve the quality\n",
    "        self.cross_encoder = CrossEncoder(cross_encoder_name)\n",
    "\n",
    "        self.passages = []\n",
    "        self.reverse_indices = []\n",
    "        for index, row in tqdm(self.all_docs.iterrows(), total=self.all_docs.shape[0]):\n",
    "            # if len(self.passages) > 50:\n",
    "            #     # Use a very small subset when debugging\n",
    "            #     break\n",
    "            data = row['doc_text']\n",
    "            first_words = \" \".join(str(data).split()[:500])  # Only take the first 500 words\n",
    "            self.passages.append(first_words)\n",
    "            self.reverse_indices.append(row['doc_number'])\n",
    "\n",
    "        print(\"Passages:\", len(self.passages))\n",
    "\n",
    "        # We encode all passages into our vector space.\n",
    "        self.corpus_embeddings = self.bi_encoder.encode(self.passages, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "    def select_candidates(self, query, query_nr=None):\n",
    "        # Get the bi-encoder hits\n",
    "        question_embedding = self.bi_encoder.encode(query, convert_to_tensor=True)\n",
    "        question_embedding = question_embedding.cuda()\n",
    "        hits = util.semantic_search(question_embedding, self.corpus_embeddings, top_k=self.top_k)\n",
    "        hits = hits[0]  # Get the hits for the first query\n",
    "        return hits\n",
    "\n",
    "    def rerank_candidates(self, candidates, query, n=None):\n",
    "        # Rank with cross-encoder\n",
    "        cross_inp = [[query, self.passages[hit['corpus_id']]] for hit in candidates]\n",
    "        cross_scores = self.cross_encoder.predict(cross_inp)\n",
    "\n",
    "        # Sort results by the cross-encoder scores\n",
    "        for idx in range(len(cross_scores)):\n",
    "            candidates[idx]['cross-score'] = cross_scores[idx]\n",
    "        hits = sorted(candidates, key=lambda x: x['cross-score'], reverse=True)\n",
    "\n",
    "        if n is not None:\n",
    "            hits = hits[0:n]\n",
    "\n",
    "        results = []\n",
    "        for hit in hits:\n",
    "            results.append(self.reverse_indices[hit['corpus_id']])\n",
    "\n",
    "        return results\n",
    "\n",
    "biCrossRetriever = BiCrossRetriever()\n",
    "recall, precision = rater.get_rating(biCrossRetriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class LuceneCrossRetriever(ReRankRetriever):\n",
    "    # Firsts selects top-k hits using lucene, then reranks them using a cross-encoder\n",
    "    lucene_retriever = LuceneRetriever()\n",
    "\n",
    "    def __init__(self, cross_encoder_name='cross-encoder/ms-marco-TinyBERT-L-2-v2', cross_encoder=None):\n",
    "        super().__init__()  #Note: If this retriever is too slow for you, you can lower the top-k value here\n",
    "        if cross_encoder is not None:\n",
    "            self.cross_encoder = cross_encoder\n",
    "        else:\n",
    "            self.cross_encoder = CrossEncoder(cross_encoder_name)\n",
    "\n",
    "    def select_candidates(self, query, query_nr=None):\n",
    "        assert query_nr is not None\n",
    "        lucene_results = self.lucene_retriever.retrieve_documents(query_nr, n=self.top_k)\n",
    "        return list(map(lambda x: {'doc_nr': x}, lucene_results))\n",
    "\n",
    "    def rerank_candidates(self, candidates, query, n=None):\n",
    "        # Rank with cross-encoder\n",
    "        cross_inp = [[query, DocumentRetriever.doc_nr_to_text(hit['doc_nr'])] for hit in candidates]\n",
    "        cross_scores = self.cross_encoder.predict(cross_inp)\n",
    "\n",
    "        # Sort results by the cross-encoder scores\n",
    "        for idx in range(len(cross_scores)):\n",
    "            candidates[idx]['cross-score'] = cross_scores[idx]\n",
    "        hits = sorted(candidates, key=lambda x: x['cross-score'], reverse=True)\n",
    "\n",
    "        if n is not None:\n",
    "            hits = hits[0:n]\n",
    "\n",
    "        results = []\n",
    "        for hit in hits:\n",
    "            results.append(hit['doc_nr'])\n",
    "\n",
    "        return results\n",
    "\n",
    "luceneCrossRetriever = LuceneCrossRetriever()\n",
    "recall, precision = rater.get_rating(luceneCrossRetriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Rater changes\n",
    "This initially gave the same results as the LuceneRetriever, which is probably the best possible result for recall@10 and precission@10, because the ground truth was probably based on Lucene. This means that I'll have to change the rater.\n",
    "First thing we might consider, is lowering the number of elements that get retrieved when creating the recall and the precission (currently n=10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [00:00<00:00, 1166.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.44875776397515527, Precision@1: 0.44875776397515527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [00:00<00:00, 1149.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@3: 0.4860248447204972, Precision@3: 0.4860248447204972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [00:00<00:00, 1154.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5: 0.4885093167701864, Precision@5: 0.4885093167701864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [00:00<00:00, 1137.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.49958099181701693, Precision@10: 0.49642857142857183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [00:00<00:00, 1017.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@50: 1.0, Precision@50: 0.5026468846546215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.5026468846546215)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rater.get_rating(luceneRetriever, 1)\n",
    "rater.get_rating(luceneRetriever, 3)\n",
    "rater.get_rating(luceneRetriever, 5)\n",
    "rater.get_rating(luceneRetriever, 10)\n",
    "rater.get_rating(luceneRetriever, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copy of the original output (since this might get lost when reexecuting):\n",
    "```\n",
    "100%|██████████| 644/644 [00:00<00:00, 917.35it/s]\n",
    "Recall: 0.03274476976210539, Precision: 1.0\n",
    "100%|██████████| 644/644 [00:00<00:00, 993.27it/s]\n",
    "Recall: 0.0982343092863159, Precision: 1.0\n",
    "100%|██████████| 644/644 [00:00<00:00, 1002.92it/s]\n",
    "Recall: 0.16372384881052623, Precision: 1.0\n",
    "100%|██████████| 644/644 [00:00<00:00, 877.29it/s]\n",
    "Recall: 0.32744769762105247, Precision: 1.0\n",
    "100%|██████████| 644/644 [00:00<00:00, 914.63it/s]\n",
    "Recall: 1.0, Precision: 0.9993899733806567\n",
    "```\n",
    "The precision remains kind off the same (only whith n=50 it's not 1.0, but that's probably because the ground truth doesn't have 50 matches for everything).\n",
    "The recall gets higher, which makes sense, since more of the results get retrieved.\n",
    "This is still not what we want, since we can't compare our models this way.\n",
    "\n",
    "### Relevant only\n",
    "I'm just stupied, I forgot to only use the relevant documents :facepalm: The code above has been updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [00:00<00:00, 1120.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.44875776397515527, Precision@1: 0.44875776397515527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [00:00<00:00, 1136.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@3: 0.4860248447204972, Precision@3: 0.4860248447204972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [00:00<00:00, 1166.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5: 0.4885093167701864, Precision@5: 0.4885093167701864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [00:00<00:00, 1158.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.49958099181701693, Precision@10: 0.49642857142857183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [00:00<00:00, 1156.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@50: 1.0, Precision@50: 0.5026468846546215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.5026468846546215)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rater.get_rating(luceneRetriever, 1)\n",
    "rater.get_rating(luceneRetriever, 3)\n",
    "rater.get_rating(luceneRetriever, 5)\n",
    "rater.get_rating(luceneRetriever, 10)\n",
    "rater.get_rating(luceneRetriever, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ground truth top-k only\n",
    "Appearently, the results in the ground truth are also ranked based on relvance, I can also here just use the top-k instead of always comparing with all relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/644 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "612a439534f04361897e105cb107ddc2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.44875776397515527, Precision@1: 0.44875776397515527\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/644 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8d608085aec47589262879721002c22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@3: 0.4860248447204972, Precision@3: 0.4860248447204972\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/644 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5cf7d07cd62b464ea380b7c81de6954c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5: 0.4885093167701864, Precision@5: 0.4885093167701864\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/644 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f555575a3a645639e9f58d18c728434"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.49958099181701693, Precision@10: 0.49642857142857183\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/644 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cdaf4ff71d1474bad27d01855dab752"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@50: 1.0, Precision@50: 0.5026468846546215\n"
     ]
    },
    {
     "data": {
      "text/plain": "(1.0, 0.5026468846546215)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rater.get_rating(luceneRetriever, 1)\n",
    "rater.get_rating(luceneRetriever, 3)\n",
    "rater.get_rating(luceneRetriever, 5)\n",
    "rater.get_rating(luceneRetriever, 10)\n",
    "rater.get_rating(luceneRetriever, 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Intermediate Results\n",
    "Here is an overview of the results we got so far:\n",
    "\n",
    "| Name                       | Recall@10 | Precission@10 |\n",
    "|----------------------------|-----------|---------------|\n",
    "| GroundTruthRetriever       | 1.00000   | 1.00000       |\n",
    "| LuceneRetriever            | 0.49958   | 0.49642       |\n",
    "| Bm25Retriever              | 0.43229   | 0.56536       |\n",
    "| BiCrossRetriever (MsMarco) | 0.25137   | 0.30258       |\n",
    "| LuceneCrossRetriever       | 0.43721   | 0.43416       |\n",
    "\n",
    "The LuceneRetriever is currently still having the best recall and the best precission is for the Bm25Retriever, which also isn't a neural retrieval model (besides the GroundTruthRetriever of course, which is perfect).\n",
    "Strangely, the BiCrossRetriever is the worst of them all, so I'll try to improve the LuceneCrossRetriever.\n",
    "\n",
    "# CrossEncoders\n",
    "The LuceneRetriever is currently working the best, so try this one with some different CrossEncoders.\n",
    "I tested some pretrained models listed in the [documentation](https://www.sbert.net/docs/pretrained_cross-encoders.html)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms-marco-TinyBERT-L-2-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/644 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 4.00 GiB total capacity; 2.73 GiB already allocated; 0 bytes free; 2.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18276/3435503385.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m# The one we tried earlier\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'ms-marco-TinyBERT-L-2-v2'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mrater\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_rating\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mLuceneCrossRetriever\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'cross-encoder/ms-marco-TinyBERT-L-2-v2'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;31m# A more powerfull version of the Ms-Marco (but takes more time)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18276/3578554420.py\u001B[0m in \u001B[0;36mget_rating\u001B[1;34m(self, retriever, n)\u001B[0m\n\u001B[0;32m     32\u001B[0m             \u001B[0mquery_nr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mquery\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Query_number'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m             \u001B[0mrecall\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprecision\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msingle_query_recall_precission\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery_nr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretriever\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m             \u001B[0mprecision_sum\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mprecision\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18276/3578554420.py\u001B[0m in \u001B[0;36msingle_query_recall_precission\u001B[1;34m(self, query_nr, n, retriever)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0msingle_query_recall_precission\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mquery_nr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretriever\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m         \u001B[0mquery_results\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mretriever\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieve_documents\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery_nr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m         \u001B[0mground_truth\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mground_truth_retriever\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieve_documents\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery_nr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18276/118289037.py\u001B[0m in \u001B[0;36mretrieve_documents\u001B[1;34m(self, query_nr, n)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[1;31m# Re-rank those matches\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m         \u001B[0mranked\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrerank_candidates\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhits\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mquery\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mranked\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18276/3005464072.py\u001B[0m in \u001B[0;36mrerank_candidates\u001B[1;34m(self, candidates, query, n)\u001B[0m\n\u001B[0;32m     20\u001B[0m         \u001B[1;31m# Rank with cross-encoder\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m         \u001B[0mcross_inp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mquery\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mDocumentRetriever\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdoc_nr_to_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhit\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'doc_nr'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mhit\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcandidates\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m         \u001B[0mcross_scores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcross_encoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcross_inp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[1;31m# Sort results by the cross-encoder scores\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, sentences, batch_size, show_progress_bar, num_workers, activation_fct, apply_softmax, convert_to_numpy, convert_to_tensor)\u001B[0m\n\u001B[0;32m    272\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    273\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mfeatures\u001B[0m \u001B[1;32min\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 274\u001B[1;33m                 \u001B[0mmodel_predictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_dict\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    275\u001B[0m                 \u001B[0mlogits\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mactivation_fct\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_predictions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlogits\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    276\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1538\u001B[0m         \u001B[0mreturn_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreturn_dict\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mreturn_dict\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muse_return_dict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1539\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1540\u001B[1;33m         outputs = self.bert(\n\u001B[0m\u001B[0;32m   1541\u001B[0m             \u001B[0minput_ids\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1542\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    997\u001B[0m             \u001B[0mpast_key_values_length\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpast_key_values_length\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    998\u001B[0m         )\n\u001B[1;32m--> 999\u001B[1;33m         encoder_outputs = self.encoder(\n\u001B[0m\u001B[0;32m   1000\u001B[0m             \u001B[0membedding_output\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1001\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mextended_attention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    583\u001B[0m                 )\n\u001B[0;32m    584\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 585\u001B[1;33m                 layer_outputs = layer_module(\n\u001B[0m\u001B[0;32m    586\u001B[0m                     \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    587\u001B[0m                     \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    470\u001B[0m         \u001B[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    471\u001B[0m         \u001B[0mself_attn_past_key_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpast_key_value\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mpast_key_value\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 472\u001B[1;33m         self_attention_outputs = self.attention(\n\u001B[0m\u001B[0;32m    473\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    474\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    400\u001B[0m         \u001B[0moutput_attentions\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    401\u001B[0m     ):\n\u001B[1;32m--> 402\u001B[1;33m         self_outputs = self.self(\n\u001B[0m\u001B[0;32m    403\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    404\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    304\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    305\u001B[0m         \u001B[1;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 306\u001B[1;33m         \u001B[0mattention_scores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery_layer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey_layer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    307\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    308\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mposition_embedding_type\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"relative_key\"\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mposition_embedding_type\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"relative_key_query\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 4.00 GiB total capacity; 2.73 GiB already allocated; 0 bytes free; 2.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# For some reason this also doesn't solve the cuda out of memory error\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# The one we tried earlier\n",
    "print('ms-marco-TinyBERT-L-2-v2')\n",
    "rater.get_rating(LuceneCrossRetriever('cross-encoder/ms-marco-TinyBERT-L-2-v2'))\n",
    "\n",
    "# A more powerfull version of the Ms-Marco (but takes more time)\n",
    "print('ms-marco-MiniLM-L-12-v2')\n",
    "rater.get_rating(LuceneCrossRetriever('cross-encoder/ms-marco-MiniLM-L-12-v2'))\n",
    "\n",
    "# SQuAD - Trained for answering questions\n",
    "print('qnli-electra-base')\n",
    "rater.get_rating(LuceneCrossRetriever('cross-encoder/qnli-electra-base'))\n",
    "\n",
    "# STSbenchmark\n",
    "print('stsb-TinyBERT-L-4')\n",
    "rater.get_rating(LuceneCrossRetriever('cross-encoder/stsb-TinyBERT-L-4'))\n",
    "rater.get_rating(LuceneCrossRetriever('cross-encoder/stsb-roberta-large'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Cuda ran out of memory with the last one, so I copy pasted the output here and reran the last rater:\n",
    "```\n",
    "ms-marco-TinyBERT-L-2-v2\n",
    "100%|██████████| 644/644 [01:35<00:00,  6.72it/s]\n",
    "Recall@10: 0.4372165532879821, Precision@10: 0.4341614906832301\n",
    "ms-marco-MiniLM-L-12-v2'\n",
    "100%|██████████| 644/644 [11:33<00:00,  1.08s/it]\n",
    "Recall@10: 0.4507622251799272, Precision@10: 0.4478260869565217\n",
    "qnli-electra-base\n",
    "100%|██████████| 644/644 [34:20<00:00,  3.20s/it]\n",
    "Recall@10: 0.36328564034309485, Precision@10: 0.3605590062111812\n",
    "stsb-TinyBERT-L-4\n",
    "100%|██████████| 644/644 [03:28<00:00,  3.09it/s]\n",
    "Recall@10: 0.33324028886917134, Precision@10: 0.33090062111801294\n",
    "  0%|          | 1/644 [00:06<1:11:40,  6.69s/it]\n",
    " ---------------------------------------------------------------------------\n",
    "\n",
    "RuntimeError                              Traceback (most recent call last)\n",
    " ```\n",
    "The last one keeps giving an out of memory error, but since the other STSB Cross-Encoder didn't give that good results, I won't spend more time on trying to fix it (since I already wasted quite some time trying to fix this).\n",
    "\n",
    "## Overview LuceneCrossRetriever\n",
    "\n",
    "| Name                                    | Recall@10 | Precission@10 | Time       |\n",
    "|-----------------------------------------|-----------|---------------|------------|\n",
    "| LuceneRetriever                         | 0.49958   | 0.49642       | 431.44it/s |\n",
    "| BiCrossRetriever (MsMarco)              | 0.24137   | 0.30258       | 1.62it/s   |\n",
    "| LuceneCrossRetriever (MsMarco-TinyBERT) | 0.43721   | 0.43416       | 6.72it/s   |\n",
    "| LuceneCrossRetriever (MsMarco-MiniLM)   | 0.45076   | 0.44782       | 1.08s/it   |\n",
    "| LuceneCrossRetriever (QNLI)             | 0.36328   | 0.36055       | 3.20s/it   |\n",
    "| LuceneCrossRetriever (STSB-TinyBERT)    | 0.33324   | 0.33090       | 3.09it/s   |\n",
    "| LuceneCrossRetriever (STSB-Roberta)     | ERROR     | ERROR         | ERROR      |\n",
    "\n",
    "The original LuceneRetriver remains the best one. Based on those results, I select the MsMarco-TinyBERT pretrained model to train further.\n",
    "The MsMarco-MiniLM is slightly better, but the 6x speed difference is not worth it.\n",
    "\n",
    "## Training\n",
    "I currently only used pretrained models, without training themselves further.\n",
    "Let's try the same training as in `experiments.ipynb`.\n",
    "Since our final task is to re-rank the (small number of) results in the test dataset (and because the LuceneRetriever scored better than the BiCrossRetriever), it wouldn't be really usefull to train a bi-encoder, but we can immediately try to train a cross-encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This was some code to try to get my GPU to work (which is quite important for faster training)\n",
    "# updating my cuda driver, installing pytorch accoording to their site https://pytorch.org/ and restarting my computer solved this after a lot of struggling\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\" # Since GPU 0 won't work on my laptop\n",
    "# import torch\n",
    "# available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "# available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_training = pd.read_csv(\"data/training_data.csv\")\n",
    "\n",
    "# Use 80% of the training dataset as training data, the other 20% is validation data\n",
    "# We can't use the dev_data.csv for our evaluator, since this dataset will already be used for testing\n",
    "# src: https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "train_data = all_training.sample(frac=0.8, random_state=0)  #random state is a seed value\n",
    "dev_data = all_training.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112000/112000 [00:04<00:00, 25212.32it/s]\n",
      "100%|██████████| 28000/28000 [00:01<00:00, 25201.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "\n",
    "def get_sample_list(df):\n",
    "    samples = []\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        query = str(row['Query'])\n",
    "        doc_text = str(row['doc_text'])\n",
    "\n",
    "        label = float(row['label'])\n",
    "\n",
    "        inp_example = InputExample(texts=[query, doc_text], label=label)\n",
    "\n",
    "        samples.append(inp_example)\n",
    "    return samples\n",
    "\n",
    "\n",
    "train_samples = get_sample_list(train_data)\n",
    "dev_samples = get_sample_list(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-02 17:06:26 - Load pretrained SentenceTransformer: cross-encoder/ms-marco-TinyBERT-L-2-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\arnod/.cache\\torch\\sentence_transformers\\cross-encoder_ms-marco-TinyBERT-L-2-v2 were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-02 17:06:30 - No sentence-transformers model found with name C:\\Users\\arnod/.cache\\torch\\sentence_transformers\\cross-encoder_ms-marco-TinyBERT-L-2-v2. Creating a new one with MEAN pooling.\n",
      "2022-01-02 17:06:30 - Use pytorch device: cuda\n",
      "2022-01-02 17:06:30 - Read the train dataset\n",
      "2022-01-02 17:06:30 - Read dev dataset\n",
      "2022-01-02 17:06:30 - Warmup-steps: 2800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090d2503b2ab442dbc270499c142bf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd470fd85838441fb7fb6b652bbffcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-02 17:28:31 - EmbeddingSimilarityEvaluator: Evaluating the model on ms-marco dataset after epoch 0:\n",
      "2022-01-02 17:32:33 - Cosine-Similarity :\tPearson: 0.2840\tSpearman: 0.2783\n",
      "2022-01-02 17:32:33 - Manhattan-Distance:\tPearson: 0.2704\tSpearman: 0.2648\n",
      "2022-01-02 17:32:33 - Euclidean-Distance:\tPearson: 0.2760\tSpearman: 0.2707\n",
      "2022-01-02 17:32:33 - Dot-Product-Similarity:\tPearson: 0.2749\tSpearman: 0.2686\n",
      "2022-01-02 17:32:33 - Save model to output/training-cross-encoder/ms-marco-TinyBERT-L-2-v2-b16e4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cc63a2edc340b2b3f4daae3e9eebe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-02 17:53:57 - EmbeddingSimilarityEvaluator: Evaluating the model on ms-marco dataset after epoch 1:\n",
      "2022-01-02 17:59:55 - Cosine-Similarity :\tPearson: 0.3307\tSpearman: 0.3259\n",
      "2022-01-02 17:59:55 - Manhattan-Distance:\tPearson: 0.3180\tSpearman: 0.3128\n",
      "2022-01-02 17:59:55 - Euclidean-Distance:\tPearson: 0.3233\tSpearman: 0.3174\n",
      "2022-01-02 17:59:55 - Dot-Product-Similarity:\tPearson: 0.3143\tSpearman: 0.3082\n",
      "2022-01-02 17:59:55 - Save model to output/training-cross-encoder/ms-marco-TinyBERT-L-2-v2-b16e4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637c051837be4d04b84cb7ef1ccf8fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-02 18:19:48 - EmbeddingSimilarityEvaluator: Evaluating the model on ms-marco dataset after epoch 2:\n",
      "2022-01-02 18:23:05 - Cosine-Similarity :\tPearson: 0.3451\tSpearman: 0.3415\n",
      "2022-01-02 18:23:05 - Manhattan-Distance:\tPearson: 0.3336\tSpearman: 0.3279\n",
      "2022-01-02 18:23:05 - Euclidean-Distance:\tPearson: 0.3384\tSpearman: 0.3320\n",
      "2022-01-02 18:23:05 - Dot-Product-Similarity:\tPearson: 0.3342\tSpearman: 0.3291\n",
      "2022-01-02 18:23:05 - Save model to output/training-cross-encoder/ms-marco-TinyBERT-L-2-v2-b16e4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4416a277ab624e989ffc543b36eea8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-02 18:42:08 - EmbeddingSimilarityEvaluator: Evaluating the model on ms-marco dataset after epoch 3:\n",
      "2022-01-02 18:45:37 - Cosine-Similarity :\tPearson: 0.3496\tSpearman: 0.3469\n",
      "2022-01-02 18:45:37 - Manhattan-Distance:\tPearson: 0.3398\tSpearman: 0.3344\n",
      "2022-01-02 18:45:37 - Euclidean-Distance:\tPearson: 0.3438\tSpearman: 0.3379\n",
      "2022-01-02 18:45:37 - Dot-Product-Similarity:\tPearson: 0.3404\tSpearman: 0.3361\n",
      "2022-01-02 18:45:37 - Save model to output/training-cross-encoder/ms-marco-TinyBERT-L-2-v2-b16e4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19608/1001096373.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[1;31m# Training done, now evaluate the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m \u001B[0mluceneCrossRetriever\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mLuceneCrossRetriever\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_save_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m \u001B[0mrecall\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprecision\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrater\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_rating\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mluceneCrossRetriever\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from sentence_transformers import InputExample\n",
    "import pandas as pd\n",
    "\n",
    "# Code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "\n",
    "\n",
    "def train_model(train_samples, dev_samples, model_name, train_batch_size, num_epochs, model_save_path):\n",
    "    # Load a pre-trained sentence transformer model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "    train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "    evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='ms-marco')\n",
    "\n",
    "    # Configure the training. We skip evaluation in this example\n",
    "    warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  #10% of train data for warm-up\n",
    "    logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "              evaluator=evaluator,\n",
    "              epochs=num_epochs,\n",
    "              warmup_steps=warmup_steps,\n",
    "              output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at output/training-cross-encoder/ms-marco-TinyBERT-L-2-v2-b16e4 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating again, since error after training\n",
      "Calculating score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [01:18<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.2834966232869955, Precision@10: 0.28121118012422314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'cross-encoder/ms-marco-TinyBERT-L-2-v2'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = f'output/training-{model_name}-b{train_batch_size}e{num_epochs}'\n",
    "\n",
    "train_model(train_samples, dev_samples, model_name, train_batch_size, num_epochs, model_save_path)\n",
    "\n",
    "# Training done, now evaluate the model\n",
    "print(\"Evaluating again, since error after training\")\n",
    "luceneCrossRetriever = LuceneCrossRetriever(model_save_path)\n",
    "print(\"Calculating score\")\n",
    "recall, precision = rater.get_rating(luceneCrossRetriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here is an overview:\n",
    "\n",
    "| Name                         | Recall@10 | Precission@10 |\n",
    "|------------------------------|-----------|---------------|\n",
    "| LuceneRetriever              | 0.49958   | 0.49642       |\n",
    "| BiCrossRetriever (MsMarco)   | 0.25137   | 0.30258       |\n",
    "| LuceneCrossRetriever         | 0.43721   | 0.43416       |\n",
    "| Trained LuceneCrossRetriever Attempt 1 | 0.28349   | 0.28121       |\n",
    "\n",
    "## Better attempt?\n",
    "The training makes it even worse (which is very strange). This is probably because I just used a standard losses function instead of searching one for our specific use case.\n",
    "As mentioned multiple times in the documentation, there is no One-Size-Fits-All loss-function, but the loss function I used was clearly one that wasn't inteded for a cross-encoder.\n",
    "To find the right function, I took a look at the [losses documentation](https://www.sbert.net/docs/package_reference/losses.html), but here wasn't anything explicitly mentioned for training cross-encoder. However, there were some training examples on the [Cross-Encoders page](https://www.sbert.net/examples/training/cross-encoder/README.html).\n",
    "By looking at [one of the examples](https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/cross-encoder/training_stsbenchmark.py), the main difference was the evaluator and they didn't provide any loss function, so let's also try to do that. I also used a SentenceTransformer as model instead of a CrossEncoder, so I made quite some mistakes that might declare the worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112000/112000 [00:04<00:00, 25729.38it/s]\n",
      "100%|██████████| 28000/28000 [00:01<00:00, 23608.08it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5764b0773d9b48aa82fe3a0aa32c4383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68b33edc5894b638252358135ddfde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8978d7828ea14b9a8ac223f9de57e1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba029a8c934b4554928a145f7bd48c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5384a98bfb46559c7329917f8c4992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [01:38<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.5427265108942125, Precision@10: 0.5392857142857139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "# For some reason, I can't reuse a sample list, so let's generate it again\n",
    "train_samples = get_sample_list(train_data)\n",
    "dev_samples = get_sample_list(dev_data)\n",
    "\n",
    "model_name = 'cross-encoder/ms-marco-TinyBERT-L-2-v2'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = f'output/training-{model_name}-b{train_batch_size}e{num_epochs}'\n",
    "\n",
    "model = CrossEncoder(model_name)\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(dev_samples, name='ms-marco-attempt-2')\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "# Training done, now evaluate the model\n",
    "luceneCrossRetriever = LuceneCrossRetriever(model_save_path)\n",
    "recall, precision = rater.get_rating(luceneCrossRetriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the results are getting better than Lucene :-) (That smiley is my happy face once I saw those results)\n",
    "We're now having a recall of 0.54272 and a Precision of 0.53928. Let's try some more epochs to see if things are improving that way.\n",
    "\n",
    "There is also an entire `sentence_transformers.cross_encoder.evaluation` file.\n",
    "When searching for the documentation of this file, I noticed that the documentation of the cross_encoder evaluators were listed on [another page in the documentation](https://www.sbert.net/docs/package_reference/cross_encoder.html).\n",
    "\n",
    "On this documentation page, I found that there was a CERerankingEvaluator, which is exactly the evaluator we need.\n",
    "\n",
    "We now try more epochs and use the CERerankingEvaluator to see the evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112000/112000 [00:04<00:00, 23798.97it/s]\n",
      "100%|██████████| 28000/28000 [00:01<00:00, 25827.72it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e202fa028b48c694377a4184552ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67b46f3c0ee44d1982eabdac244ee97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d99c28c7ca470eb20da51eb28f0f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29dc413fcce14a31bd3f163f906a8733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5935680501404db0535718337ede16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0766cb50003a4be9b32110dc9e671cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32a2a2aef7f40aaaceb984d96d856a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807a760ce53741f0bf828957fcfbaf65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9394fc301d8d4d73b8652e9183f1c80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cddf8d37964079b86aecce25487bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e89f710823e40029d2fc7b1a56d8323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6b917d10234a85a65f059457086f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d561ea7ae62c4582a74f53ae76e46ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82537e2626d1492b86edc331578a0c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3771b828e723480b8968ccf214b1d3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0851409105649ce9f8c47be0161d635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac281369c7914e43a7fe64f52ed030f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0696c6813c4442eb136b3572bd7c9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15553e16dae44acda5d2792a6abdc4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7810b868a44846cfa93472443db7c963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccae2c3847e94cf2bca8475ee1c3becb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [01:27<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.5391051710539284, Precision@10: 0.5357142857142855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder.evaluation import CERerankingEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "\n",
    "def get_reranking_samples(df):\n",
    "    samples = []\n",
    "    previous_query = None\n",
    "    positive = []\n",
    "    negative = []\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        query = str(row['Query'])\n",
    "        if query != previous_query and previous_query is not None:\n",
    "            samples.append({'query': query, 'positive': positive[:], 'negative': negative[:]})\n",
    "            positive = []\n",
    "            negative = []\n",
    "        doc_text = str(row['doc_text'])\n",
    "        label = float(row['label'])\n",
    "        if label == 1.0:\n",
    "            positive.append(doc_text)\n",
    "        else:\n",
    "            negative.append(doc_text)\n",
    "        previous_query = query\n",
    "    return samples\n",
    "\n",
    "\n",
    "train_samples = get_sample_list(train_data)\n",
    "dev_samples = get_reranking_samples(dev_data)\n",
    "\n",
    "model_name = 'cross-encoder/ms-marco-TinyBERT-L-2-v2'\n",
    "train_batch_size = 16\n",
    "num_epochs = 20\n",
    "model_save_path = f'output/training-{model_name}-b{train_batch_size}e{num_epochs}-attempt3'\n",
    "\n",
    "model = CrossEncoder(model_name, num_labels=1)\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "evaluator = CERerankingEvaluator(dev_samples, name='ms-marco-attempt-3')\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "# Training done, now evaluate the model\n",
    "luceneCrossRetriever = LuceneCrossRetriever(model_save_path)\n",
    "recall, precision = rater.get_rating(luceneCrossRetriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "More epochs doesn't seem to give better result, surprisingly, the results were even slightly worse.\n",
    "We now used the evaluator, so we can take a look at how the quality evolves when we do more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='epoch'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the CERerankingEvaluator data\n",
    "df = pd.read_csv(f\"{model_save_path}/CERerankingEvaluator_ms-marco-attempt-3_results.csv\")\n",
    "df.plot(x='epoch', y='MRR@10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the data we can see that it slightly gets worse when we do more epochs. The best results (on are dev data) are achieved after two epochs, so let's continue using that then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176827eb2094480c95d1d6c39eb41751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0bd853d5e54519b84cc54d8a4fcebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0ce599c35444f784d1418b065a078c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [02:05<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.5333857093562061, Precision@10: 0.5301242236024845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'cross-encoder/ms-marco-TinyBERT-L-2-v2'\n",
    "train_batch_size = 16\n",
    "num_epochs = 2\n",
    "model_save_path = f'output/training-{model_name}-b{train_batch_size}e{num_epochs}-attempt4'\n",
    "\n",
    "model = CrossEncoder(model_name, num_labels=1)\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "evaluator = CERerankingEvaluator(dev_samples, name='ms-marco-attempt-3')\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "# Training done, now evaluate the model\n",
    "luceneCrossRetriever = LuceneCrossRetriever(model_save_path)\n",
    "recall, precision = rater.get_rating(luceneCrossRetriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Our model after 4 epochs still gave a slightly better result, so let's just use that one instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112000/112000 [00:08<00:00, 13976.62it/s]\n",
      "100%|██████████| 28000/28000 [00:01<00:00, 19548.86it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d5c2a3e90f497b8a3929e02562983f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5cae253a9946a08d1b38e8448071d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1967faf1ae34e5bb96541edcbdcd27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412e4eccacf04832aa087507f74034da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696eba741d5443b88283cd4002c51fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [02:13<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.5427265108942125, Precision@10: 0.5392857142857139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# I accidentally overwritten that model, so let's try generating it again\n",
    "\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "# For some reason, I can't reuse a sample list, so let's generate it again\n",
    "train_samples = get_sample_list(train_data)\n",
    "dev_samples = get_sample_list(dev_data)\n",
    "\n",
    "model_name = 'cross-encoder/ms-marco-TinyBERT-L-2-v2'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = f'output/training-{model_name}-b{train_batch_size}e{num_epochs}'\n",
    "\n",
    "model = CrossEncoder(model_name)\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(dev_samples, name='ms-marco-attempt-2')\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "# Training done, now evaluate the model\n",
    "luceneCrossRetriever = LuceneCrossRetriever(model_save_path)\n",
    "recall, precision = rater.get_rating(luceneCrossRetriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Truncate length\n",
    "There are still a lot of hyperparameters that can be tuned, but I can keep on going endlessly if I do that.\n",
    "Since we're not going to do all of them, let's take a look at the truncate length as last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'output/training-cross-encoder/ms-marco-TinyBERT-L-2-v2-b16e4/'\n",
    "model = CrossEncoder(model_name)\n",
    "print(model.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Strangely, there is no max_length set for this model, meaning that it can just run with any input length. Let's try to set some different max_length values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating length 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [02:44<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.4056430543231791, Precision@10: 0.403260869565218\n",
      "Evaluating length 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [01:41<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.45131433007985844, Precision@10: 0.44875776397515543\n",
      "Evaluating length 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [01:42<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.47991595188800135, Precision@10: 0.47686335403726665\n",
      "Evaluating length 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [01:45<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.4861228186926945, Precision@10: 0.4829192546583851\n",
      "Evaluating length 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [02:01<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.5004492014196982, Precision@10: 0.49704968944099354\n",
      "Evaluating length 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [02:10<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.5427265108942125, Precision@10: 0.5392857142857139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x269924f8ca0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's just evaluate based on the precision\n",
    "lenght_scores = []  # Will contain tuples (max_length, score)\n",
    "\n",
    "\n",
    "def evaluate_length(max_length):\n",
    "    print(f\"Evaluating length {max_length}\")\n",
    "    model = CrossEncoder(model_name, max_length=max_length)\n",
    "    luceneCrossRetriever = LuceneCrossRetriever(cross_encoder=model)\n",
    "    recall, precision = rater.get_rating(luceneCrossRetriever)\n",
    "    return precision\n",
    "\n",
    "\n",
    "for i in [16, 32, 64, 128, 256, 512]:  # 1024]:\n",
    "    lenght_scores.append((i, evaluate_length(i)))\n",
    "\n",
    "# Plot the given lengths\n",
    "# src: https://stackoverflow.com/questions/18458734/how-do-i-plot-list-of-tuples-in-python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, y = zip(*lenght_scores)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Length 1024 causes a runtime error, but for the other values it is clear that the higher the max_length, the better the results (as expected).\n",
    "```\n",
    "RuntimeError: The size of tensor a (1024) must match the size of tensor b (512) at non-singleton dimension 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [02:02<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.5427265108942125, Precision@10: 0.5392857142857139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the model again, without a model specified\n",
    "model = CrossEncoder(model_name)\n",
    "luceneCrossRetriever = LuceneCrossRetriever(cross_encoder=model)\n",
    "recall, precision = rater.get_rating(luceneCrossRetriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "No max length specified gives the same output as when max_length = 512, but as mentioned earlier print(model.max_length) gave None. Maybe it still gets truncated at this length without having the correct variable set, but I couldn't find anything about that in\n",
    "\n",
    "## Relevance labeling\n",
    "The ModelRater currently mainly focussed on the ranking of documents.\n",
    "This is achieved by giving a score with a cross-encoder.\n",
    "To determine whether a document is relevant, we have to find a threshold for given score.\n",
    "To find ths threshold, first generate a score for all training parts and then try some different values and see how well it performs on the dev_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnod\\AppData\\Local\\Temp/ipykernel_17500/3629609854.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  query_text['Query'] = query_text['Query'].astype(str)\n",
      "C:\\Users\\arnod\\AppData\\Local\\Temp/ipykernel_17500/3629609854.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  query_text['doc_text'] = query_text['doc_text'].astype(str)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4345c932f43416cb5d9a7741db0cab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query_number</th>\n",
       "      <th>Query</th>\n",
       "      <th>doc_text</th>\n",
       "      <th>doc_number</th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>our_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>androgen receptor define</td>\n",
       "      <td>Video Writeups The Ultimate Guide to Sarms Las...</td>\n",
       "      <td>177589</td>\n",
       "      <td>37451</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.689590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>androgen receptor define</td>\n",
       "      <td>Category: SARMSSARMS Reviewed and Explained Dy...</td>\n",
       "      <td>193130</td>\n",
       "      <td>37452</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.316287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>androgen receptor define</td>\n",
       "      <td>The Hormones : Androgens Construction and Prod...</td>\n",
       "      <td>392384</td>\n",
       "      <td>37453</td>\n",
       "      <td>1</td>\n",
       "      <td>1.347050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>androgen receptor define</td>\n",
       "      <td>Theriogenology Volume 80, Issue 6, 1 October 2...</td>\n",
       "      <td>15195</td>\n",
       "      <td>37454</td>\n",
       "      <td>1</td>\n",
       "      <td>0.731395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>androgen receptor define</td>\n",
       "      <td>SARMs: The Controversial Muscle Builders of 20...</td>\n",
       "      <td>269140</td>\n",
       "      <td>37455</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.335425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Query_number                      Query  \\\n",
       "0             2   androgen receptor define   \n",
       "1             2   androgen receptor define   \n",
       "2             2   androgen receptor define   \n",
       "3             2   androgen receptor define   \n",
       "4             2   androgen receptor define   \n",
       "\n",
       "                                            doc_text  doc_number  index  \\\n",
       "0  Video Writeups The Ultimate Guide to Sarms Las...      177589  37451   \n",
       "1  Category: SARMSSARMS Reviewed and Explained Dy...      193130  37452   \n",
       "2  The Hormones : Androgens Construction and Prod...      392384  37453   \n",
       "3  Theriogenology Volume 80, Issue 6, 1 October 2...       15195  37454   \n",
       "4  SARMs: The Controversial Muscle Builders of 20...      269140  37455   \n",
       "\n",
       "   label  our_score  \n",
       "0      1  -0.689590  \n",
       "1      1  -0.316287  \n",
       "2      1   1.347050  \n",
       "3      1   0.731395  \n",
       "4      1  -1.335425  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "import pandas as pd\n",
    "\n",
    "model_name = 'output/training-cross-encoder/ms-marco-TinyBERT-L-2-v2-b16e4/'\n",
    "model = CrossEncoder(model_name)\n",
    "train_data = pd.read_csv(\"data/training_data.csv\")\n",
    "\n",
    "# Assign scores made by our crossencoder for every training element.\n",
    "# The predict function also has a show_progress_bar option, so we can just predict them all at once (while still having an idea of how long it will take)\n",
    "\n",
    "# Create the pairs for which to predict the score\n",
    "query_text = train_data[['Query', 'doc_text']]\n",
    "# There is somewhere a record that is a float instead of a string, so cast everything to a string\n",
    "query_text['Query'] = query_text['Query'].astype(str)\n",
    "query_text['doc_text'] = query_text['doc_text'].astype(str)\n",
    "# df to list op tuples (src: https://www.kite.com/python/answers/how-to-convert-a-pandas-dataframe-into-a-list-of-tuples-in-python)\n",
    "records = query_text.to_records(index=False)\n",
    "sentences = list(records)\n",
    "\n",
    "# Predict the scores\n",
    "scores = model.predict(sentences, show_progress_bar=True)\n",
    "\n",
    "train_data['our_score'] = scores  # If scores is a np array, append .tolist()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Great, we now have our scores added to the dataframe, let's see what a good threshold would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's make some plots, because that always looks fancy\n",
    "# And we can also use them to get a general idea of how our data is spread\n",
    "# positive_labels = train_data[train_data['label'] == 1]\n",
    "# negative_labels = train_data[train_data['label'] == 0]\n",
    "#\n",
    "# positive_label_scores = positive_labels[['our_score']]\n",
    "# negative_label_scores = negative_labels[['our_score']]\n",
    "#\n",
    "# positive_label_scores.boxplot()\n",
    "# negative_label_scores.boxplot()\n",
    "#\n",
    "# pos_neg_label_scores = pd.concat([positive_label_scores, negative_label_scores], keys=['positive', 'negative'])\n",
    "#\n",
    "# pos_neg_label_scores.boxplot()\n",
    "\n",
    "# All code above isn't required anymore since I found the group_by option\n",
    "boxplot = train_data.boxplot(column=['our_score'], by='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Given those boxplots, we can see that's its impossible to create a perfect threshold value, but we can try to maximize the correct predictions and minimize the wrong predictions by testing some different values. The best treshold will probably be somewhere between -0.5 and 1.5.\n",
    "\n",
    "Note: to increase the recall, we should lower the treshold and to increase the precision, we should make the treshold higher.\n",
    "\n",
    "Let's try some different possible threshold values. For this, we need an evaluation score, where we want to maximize the true positives and true negatives, and minimize the false positives and false negatives.\n",
    "In this function, the higher the score, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55848, 97924, 42076)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_threshold_score(threshold):\n",
    "    filtered_relevant = train_data[train_data['our_score'] > threshold]\n",
    "    filtered_irrelevant = train_data[train_data['our_score'] <= threshold]\n",
    "\n",
    "    true_positives = filtered_relevant[filtered_relevant['label'] == 1]\n",
    "    false_positives = filtered_relevant[filtered_relevant['label'] == 0]\n",
    "    true_negatives = filtered_irrelevant[filtered_irrelevant['label'] == 0]\n",
    "    false_negatives = filtered_irrelevant[filtered_irrelevant['label'] == 1]\n",
    "\n",
    "    total_right = true_positives.count()['label'] + true_negatives.count()['label']\n",
    "    total_wrong = false_positives.count()['label'] + false_negatives.count()['label']\n",
    "\n",
    "    # Higher score is better\n",
    "    score = total_right - total_wrong\n",
    "    return score, total_right, total_wrong\n",
    "\n",
    "\n",
    "get_threshold_score(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:00<00:01, 14.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New max with threshold -0.5: 43834\n",
      "New max with threshold -0.4: 46244\n",
      "New max with threshold -0.30000000000000004: 48624\n",
      "New max with threshold -0.20000000000000007: 50816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:00<00:00, 15.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New max with threshold -0.10000000000000009: 52482\n",
      "New max with threshold -1.1102230246251565e-16: 53628\n",
      "New max with threshold 0.09999999999999987: 54730\n",
      "New max with threshold 0.19999999999999984: 55212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:00<00:00, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New max with threshold 0.2999999999999998: 55748\n",
      "New max with threshold 0.3999999999999998: 55968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 15.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Default python range doesn't support float steps\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Test some possible threshold values\n",
    "max_score = -float(\"inf\")\n",
    "best_threshold = 0\n",
    "\n",
    "scores = []\n",
    "rights = []\n",
    "wrongs = []\n",
    "thresholds = np.arange(-0.5, 1.5, 0.1)\n",
    "for threshold in tqdm(thresholds, total=thresholds.size):\n",
    "    score, right, wrong = get_threshold_score(threshold)\n",
    "    scores.append(score)\n",
    "    rights.append(right)\n",
    "    wrongs.append(wrong)\n",
    "\n",
    "    if score > max_score:\n",
    "        print(f\"New max with threshold {threshold}: {score}\")\n",
    "        max_score = score\n",
    "        best_threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Make the plots\n",
    "# src: https://howtothink.readthedocs.io/en/latest/PvL_H.html\n",
    "plt.plot(thresholds, rights, label='Correct predictions')\n",
    "plt.plot(thresholds, wrongs, label='Incorrect predictions')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds, scores)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Based on this, we'll use a cross-encoder score of 0.4 as threshold for a document to be relevant.\n",
    "\n",
    "With this threshold, I can also generate a recall and precission for predicting labels (since I up to now only got one for recommending documents). However, the raw_dev_Lucene_retrievals.csv didn't contain a score or a label, so I can't use this as baseline to compare this recall and precission with it. The training set also only contains documents that we're retrieved, so only positives (false and true) and not negatives, so this also can't be used to get a baseline recall (but precision can be calculated with this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnod\\AppData\\Local\\Temp/ipykernel_17500/3427433875.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  query_text['Query'] = query_text['Query'].astype(str)\n",
      "C:\\Users\\arnod\\AppData\\Local\\Temp/ipykernel_17500/3427433875.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  query_text['doc_text'] = query_text['doc_text'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/625 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53f119c823544b85a4b42c299d4370bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We determined the threshold using the train_data, so use another dataset to evaluate it\n",
    "dev_data = pd.read_csv('data/dev_data.csv')\n",
    "\n",
    "query_text = dev_data[['Query', 'doc_text']]\n",
    "query_text['Query'] = query_text['Query'].astype(str)\n",
    "query_text['doc_text'] = query_text['doc_text'].astype(str)\n",
    "\n",
    "records = query_text.to_records(index=False)\n",
    "sentences = list(records)\n",
    "\n",
    "scores = model.predict(sentences, show_progress_bar=True)\n",
    "\n",
    "dev_data['our_score'] = scores  # If scores is a np array, append .tolist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.5963632730542512, 0.6802279202279202)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.4\n",
    "\n",
    "filtered_relevant = dev_data[dev_data['our_score'] > threshold]\n",
    "filtered_irrelevant = dev_data[dev_data['our_score'] <= threshold]\n",
    "\n",
    "true_positives = filtered_relevant[filtered_relevant['label'] == 1].count()['label']\n",
    "false_positives = filtered_relevant[filtered_relevant['label'] == 0].count()['label']\n",
    "true_negatives = filtered_irrelevant[filtered_irrelevant['label'] == 0].count()['label']\n",
    "false_negatives = filtered_irrelevant[filtered_irrelevant['label'] == 1].count()['label']\n",
    "\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "\n",
    "recall, precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate the baseline precision for Lucene based on the training_data.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4972142857142857"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv('data/training_data.csv')\n",
    "\n",
    "true_positives = training_data[training_data['label'] == 1].count()['label']\n",
    "false_positives = training_data[training_data['label'] == 0].count()['label']\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "\n",
    "precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test dataset\n",
    "Enough experiments, time to rate and rank the test dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/57 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5922c1c16cf94a0aa1a18dfb199cb8ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"data/test_data.csv\")\n",
    "\n",
    "query_text = test_data[['Query', 'doc_text']]  # 5 for testing purposes\n",
    "\n",
    "records = query_text.to_records(index=False)\n",
    "sentences = list(records)\n",
    "\n",
    "# Predict the scores\n",
    "scores = model.predict(sentences, show_progress_bar=True)\n",
    "\n",
    "test_data['relevance_score'] = scores\n",
    "\n",
    "# Set the labels\n",
    "# src: https://stackoverflow.com/questions/49161120/pandas-python-set-value-of-one-column-based-on-value-in-another-column\n",
    "threshold = 0.4\n",
    "test_data['label'] = np.where(test_data.relevance_score > threshold, 1, 0)\n",
    "\n",
    "sorted = test_data.sort_values(by=[\"Query_number\", \"relevance_score\"], ascending=[True, False])\n",
    "\n",
    "sorted.to_csv('neural_model_rank.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}