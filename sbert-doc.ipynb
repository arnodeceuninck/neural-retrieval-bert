{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SBERT Documentation\n",
    "Next, I took a look at the [SBERT documentation](https://sbert.net/). Note that a lot of the code below is copied from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# This is their initial example to show how easy SBERT is\n",
    "# DONE: To know which model to use, take a look at those descriptions: https://www.sbert.net/docs/pretrained_models.html#sentence-embedding-models\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "#\n",
    "# #Our sentences we like to encode\n",
    "# sentences = ['This framework generates embeddings for each input sentence',\n",
    "#     'Sentences are passed as a list of string.',\n",
    "#     'The quick brown fox jumps over the lazy dog.']\n",
    "#\n",
    "# #Sentences are encoded by calling model.encode()\n",
    "# embeddings = model.encode(sentences)\n",
    "#\n",
    "# #Print the embeddings\n",
    "# for sentence, embedding in zip(sentences, embeddings):\n",
    "#     print(\"Sentence:\", sentence)\n",
    "#     print(\"Embedding:\", embedding)\n",
    "#     print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity: tensor([[0.6153]])\n",
      "Cosine-Similarity not similar sentence: tensor([[-0.0356]])\n",
      "Cos-Sim of own similar sentences: tensor([[0.3480]])\n",
      "Cos-Sim of own more similar sentences: tensor([[0.8072]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "emb1 = model.encode(\"This is a red cat with a hat.\")\n",
    "emb2 = model.encode(\"Have you seen my red cat?\")\n",
    "emb3 = model.encode(\"I am a student at the university of Antwerp\")\n",
    "emb4 = model.encode(\"Information retrieval is given at our university\")\n",
    "emb5 = model.encode(\"Studying at the university of Antwerp is great\")\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"Cosine-Similarity:\", cos_sim)\n",
    "print(f\"Cosine-Similarity not similar sentence: {util.cos_sim(emb1, emb3)}\")\n",
    "print(f\"Cos-Sim of own similar sentences: {util.cos_sim(emb3, emb4)}\")\n",
    "print(f\"Cos-Sim of own more similar sentences: {util.cos_sim(emb3, emb5)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 most similar pairs:\n",
      "A man is eating food. \t A man is eating a piece of bread. \t 0.7553\n",
      "A man is riding a horse. \t A man is riding a white horse on an enclosed ground. \t 0.7369\n",
      "A monkey is playing drums. \t Someone in a gorilla costume is playing a set of drums. \t 0.6433\n",
      "A woman is playing violin. \t Someone in a gorilla costume is playing a set of drums. \t 0.2564\n",
      "A man is eating food. \t A man is riding a horse. \t 0.2474\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "sentences = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.'\n",
    "          ]\n",
    "\n",
    "#Encode all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])\n",
    "\n",
    "#Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations[0:5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))\n",
    "\n",
    "# TODO: For training own embeddings, I have to take a look here: https://sbert.net/docs/training/overview.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretrained models\n",
    "Currently on [this page](https://sbert.net/docs/pretrained_models.html) of the tutorial.\n",
    "\n",
    "By reading the description of the models, those where the one that seemed interesting to me:\n",
    "- multi-qa-mpnet-base-dot-v1:   This model was tuned for semantic search: Given a query/question, if can find relevant passages. It was trained on a large and diverse set of (question, answer) pairs.\n",
    "- multi-qa-distilbert-cos-v1: \tThis model was tuned for semantic search: Given a query/question, if can find relevant passages. It was trained on a large and diverse set of (question, answer) pairs. (twice as fast as the one above)\n",
    "- multi-qa-MiniLM-L6-cos-v1: \tThis model was tuned for semantic search: Given a query/question, if can find relevant passages. It was trained on a large and diverse set of (question, answer) pairs. (six times as fast as the first one)\n",
    "- all-mpnet-base-v2: All-round model tuned for many use-cases. Trained on a large and diverse dataset of over 1 billion training pairs.\n",
    "- all-MiniLM-L12-v2: All-round model tuned for many use-cases. Trained on a large and diverse dataset of over 1 billion training pairs. (the faster version)\n",
    "\n",
    "## Semantic search\n",
    "There are also more models trained specifically on semantic search, which is what we need."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.5472, 0.6330, 0.0656, 0.9003, 0.6642]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "query_embedding = model.encode('How big is London')\n",
    "passage_embedding = model.encode(['London has 9,787,426 inhabitants at the 2011 census',\n",
    "                                  'London is known for its finacial district',\n",
    "                                  'I like trains',\n",
    "                                  'London is very large',\n",
    "                                  'London is bigger than Middelheim'])\n",
    "\n",
    "print(\"Similarity:\", util.dot_score(query_embedding, passage_embedding))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-QA Models\n",
    "Those where the first three mentioned from my list above and have been trained on 215M question-answer pairs from various sources and domains, including StackExchange, Yahoo Answers, Google & Bing search queries and many more. These model perform well across many search tasks and domains accoording to the site, so I definetly have to try them.\n",
    "\n",
    "#### Bing dataset\n",
    "- msmarco-bert-base-dot-v5\n",
    "\n",
    "Since all our documents are in English, we don't need multi-lingual models.\n",
    "\n",
    "## Pretrained cross-encoders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.1523705 -6.287044 ]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "model = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-2-v2', max_length=512)\n",
    "scores = model.predict([('Query1', 'Paragraph1'), ('Query1', 'Paragraph2')])\n",
    "\n",
    "#For Example\n",
    "scores = model.predict([('How many people live in Berlin?', 'Berlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.'),\n",
    "                        ('How many people live in Berlin?', 'Berlin is well known for its museums.')])\n",
    "print(scores)\n",
    "# TODO: Take a better look at Retrieve & Re-Rank: https://sbert.net/examples/applications/retrieve_rerank/README.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entailment', 'contradiction']\n"
     ]
    }
   ],
   "source": [
    "# This is not useful for the assignment, but just seemed cool to me (also similar to the tutorials mentioned in the assignment)\n",
    "from sentence_transformers import CrossEncoder\n",
    "model = CrossEncoder('cross-encoder/nli-distilroberta-base')\n",
    "scores = model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])\n",
    "\n",
    "# Convert scores to labels\n",
    "label_mapping = ['contradiction', 'entailment', 'neutral']\n",
    "labels = [label_mapping[score_max] for score_max in scores.argmax(axis=1)]\n",
    "print(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "Take a look [here](https://sbert.net/docs/publications.html) for the references, I think the only required citations I used are the repo and MSMacro.\n",
    "\n",
    "# Computing embeddings\n",
    "I'm currently on [this](https://sbert.net/examples/applications/computing-embeddings/README.html) tutorial page.\n",
    "## Input sequence length\n",
    "As mentioned in one of the earlier tutorial, the longer texts must be truncated.\n",
    ">  Transformer models like BERT / RoBERTa / DistilBERT etc. the runtime and the memory requirement grows quadratic with the input length. This limits transformers to inputs of certain lengths. A common value for BERT & Co. are 512 word pieces, which corresponde to about 300-400 words (for English). Longer texts than this are truncated to the first x word pieces.\n",
    "\n",
    "By default, there is a limit of 128 word pieces. Let's take a look at our length distribution graph mentioned in the previous tutorial:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# See how long the text information is\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/training_data.csv\")\n",
    "# Note: Loading the dataframe is put in a different cell to prevent longer loads"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg. doc_len: 1812.0840857142857\n",
      "max_seq_len: 5148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arnod\\pycharmprojects\\neural-retrieval-bert\\venv\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df['doc_len'] = df['doc_text'].apply(lambda words: len(str(words).split()))\n",
    "print(f\"avg. doc_len: {df['doc_len'].mean()}\")\n",
    "max_seq_len = np.round(df['doc_len'].mean() + df['doc_len'].std()).astype(int)\n",
    "print(f\"max_seq_len: {max_seq_len}\")\n",
    "sns.distplot(df['doc_len'], hist=True, kde=True, color='r', label='doc len')\n",
    "plt.axvline(x=max_seq_len, color='k', linestyle='--', label='max len')\n",
    "plt.title('plot length'); plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Get an idea of the number of entries:\n",
    "index = df.index\n",
    "number_of_rows = len(index)\n",
    "print(f\"Training data number of rows: {number_of_rows}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, the average text length is 1812 words, by adding the standard deviation to this, we get a max_sequence length of 5148 (based on what the previous tutorial described as max sequence length), which is quite long for the models. We can however change the max length for a model, but this will lead to a lot longer times as described above, so this will be a challenge we'll have to face later on. Currently, we'll just assume the first 256 words of a document will contain enough information to determine whether it's relevant for a query.\n",
    "> Note: You cannot increase the length higher than what is maximally supported by the respective transformer model. Also note that if a model was trained on short texts, the representations for long texts might not be that good"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 256\n",
      "Max Sequence Length: 5148\n"
     ]
    }
   ],
   "source": [
    "# Example of how to change the max sequence length\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Max Sequence Length:\", model.max_seq_length)\n",
    "\n",
    "#Change the length to 200\n",
    "model.max_seq_length = 5148\n",
    "\n",
    "print(\"Max Sequence Length:\", model.max_seq_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Storing & Loading embeddings\n",
    "When we have made embeddings for all sentences, we can store and load them as follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.',\n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Store sentences & embeddings on disc\n",
    "with open('embeddings.pkl', \"wb\") as fOut:\n",
    "    pickle.dump({'sentences': sentences, 'embeddings': embeddings}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#Load sentences & embeddings from disc\n",
    "with open('embeddings.pkl', \"rb\") as fIn:\n",
    "    stored_data = pickle.load(fIn)\n",
    "    stored_sentences = stored_data['sentences']\n",
    "    stored_embeddings = stored_data['embeddings']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Semantic search\n",
    "I'm currently at [this](https://sbert.net/examples/applications/semantic-search/README.html) page of the tutorial.\n",
    "As mentioned earlier, it is clear that we're having a case of Assymetric Search:\n",
    "> For asymmetric semantic search, you usually have a short query (like a question or some keywords) and you want to find a longer paragraph answering the query. An example would be a query like “What is Python” and you wand to find the paragraph “Python is an interpreted, high-level and general-purpose programming language. Python’s design philosophy …”. For asymmetric tasks, flipping the query and the entries in your corpus usually does not make sense.\n",
    "\n",
    "The [MsMacro models](https://www.sbert.net/docs/pretrained-models/msmarco-v3.html) should be suitable for asymetric search.\n",
    "\n",
    "Because we're working with longer passages, we'll follow this note and work with the models that are tuned to work with the dot product.\n",
    "> Models tuned for cosine-similarity will prefer the retrieval of shorter passages, while models for dot-product will prefer the retrieval of longer passages. Depending on your task, you might prefer the one or the other type of model.\n",
    "\n",
    "I'll use `msmarco-distilbert-base-tas-b` as model, since this seems the best option for our scenario accoording to the tutorial.\n",
    "\n",
    "Both models are tuned to work with cosine-similarity\n",
    "\n",
    "We've already seen that our training data contains 140.000 rows. Let's take a look at how many documents there are.\n",
    "```shell\n",
    "wc -l data/all_docs.csv\n",
    "```\n",
    "> 126204 data/all_docs.csv\n",
    "\n",
    "This is a small corpora (less than 1 million entries), so we can probably compute the dot product for all documents.\n",
    "\n",
    "Here's an example for semantic search from the tutorial:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A man is eating pasta.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A man is eating food. (Score: 0.7035)\n",
      "A man is eating a piece of bread. (Score: 0.5272)\n",
      "A man is riding a horse. (Score: 0.1889)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1047)\n",
      "A cheetah is running behind its prey. (Score: 0.0980)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Someone in a gorilla costume is playing a set of drums.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A monkey is playing drums. (Score: 0.6433)\n",
      "A woman is playing violin. (Score: 0.2564)\n",
      "A man is riding a horse. (Score: 0.1389)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1191)\n",
      "A cheetah is running behind its prey. (Score: 0.1080)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A cheetah chases prey on across a field.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A cheetah is running behind its prey. (Score: 0.8253)\n",
      "A man is eating food. (Score: 0.1399)\n",
      "A monkey is playing drums. (Score: 0.1292)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1097)\n",
      "A man is riding a horse. (Score: 0.0650)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a simple application for sentence embeddings: semantic search\n",
    "\n",
    "We have a corpus with various sentences. Then, for a given query sentence,\n",
    "we want to find the most similar sentence in this corpus.\n",
    "\n",
    "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
    "\"\"\"\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'A cheetah is running behind its prey.'\n",
    "          ]\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['A man is eating pasta.', 'Someone in a gorilla costume is playing a set of drums.', 'A cheetah chases prey on across a field.']\n",
    "\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = min(5, len(corpus))\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "\n",
    "    \"\"\"\n",
    "    # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "    hits = hits[0]      #Get the hits for the first query\n",
    "    for hit in hits:\n",
    "        print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n",
    "    \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SBERT also has a `sentence_transformers.util.semantic_search` function built in, which might be a better choice than performing the search manually like the code above.\n",
    "More info can be found [here](https://sbert.net/examples/applications/semantic-search/README.html#sentence_transformers.util.semantic_search).\n",
    "\n",
    "An example of Aproximate Nearest Neighbours (ANN) in case finding the exact top-k is too large, can be found [here](https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/semantic-search/semantic_search_quora_hnswlib.py).\n",
    "\n",
    "An example of a retrieve-rerank on the wikipedia paragraphs can be found [here](https://sbert.net/examples/applications/semantic-search/README.html#question-answer-retrieval).\n",
    "\n",
    "## Bi-encoder\n",
    "This maps the query into the same vector space as your documents and loos at the nearest documents.\n",
    "\n",
    "## Cross-encoder\n",
    "Can be used for reranking the (e.g. 100) potentially irrelevant results from the Bi-encoder. This outputs a score between 0 and 1, representing how relevant the document is for the given query.\n",
    "TODO: Continue from here: https://sbert.net/examples/applications/retrieve_rerank/README.html#example-scripts\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}